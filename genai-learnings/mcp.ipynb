{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fee1453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64dfc78",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FastMCP.run() got an unexpected keyword argument 'host'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 3. Run the server (defaults to HTTP on /mcp)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 3️⃣ Run over Streamable HTTP (not STDIO), which spins up a Uvicorn server\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43mmcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstreamable-http\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Use HTTP transport instead of STDIO :contentReference[oaicite:0]{index=0}\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m127.0.0.1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mcp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m# Mount point for JSON-RPC requests\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: FastMCP.run() got an unexpected keyword argument 'host'"
     ]
    }
   ],
   "source": [
    "# server.py\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# 1. Instantiate the server\n",
    "mcp = FastMCP(\n",
    "    \"DemoServer\",\n",
    "    host=\"127.0.0.1\",\n",
    "    port=8000,\n",
    "    streamable_http_path=\"/mcp\"  # Configure path in constructor\n",
    ")\n",
    "\n",
    "# 2. Define a tool that sums two numbers\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Return the sum of a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 3. Run the server (defaults to HTTP on /mcp)\n",
    "# 3️⃣ Run over Streamable HTTP (not STDIO), which spins up a Uvicorn server\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(\n",
    "        transport=\"streamable-http\"    # Use HTTP transport instead of STDIO :contentReference[oaicite:0]{index=0}\n",
    "                                        # host, port, and path removed from here\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with streamablehttp_client(\"http://localhost:8000/mcp\") as (read_stream, write_stream, _):\n",
    "    async with ClientSession(read_stream, write_stream) as session:\n",
    "        await session.initialize()\n",
    "        result    = await session.call_tool(tool_name, arguments=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd327a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 6. Invoke the MCP tool asynchronously\n",
    "    try:\n",
    "        result = await session.call_tool(tool_name, arguments=params)\n",
    "        print(f\"Result from '{tool_name}':\\n{result}\")\n",
    "    except MCPError as e:\n",
    "        print(f\"MCP Error ({e.code}): {e.message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    # 1. Initialize the OpenAI LLM and the MCP client\n",
    "    llm = OpenAI(api_key=\"OPENAI_API_KEY\") # Removed model=\"gpt-4\"\n",
    "    mcp = MCPClient(base_url=\"http://localhost:8000\", api_key=\"MCP_API_KEY\")\n",
    "\n",
    "    # 2. User request that requires reading a file via MCP\n",
    "    user_request = \"Please show me the first 5 lines of /var/log/syslog\"\n",
    "\n",
    "    # 3. Instruct the model to output a JSON-formatted tool call when needed\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that can call MCP tools via JSON-RPC. \"\n",
    "        \"When you need to use a tool, respond *only* with a JSON object \"\n",
    "        \"containing 'tool' and 'params', and nothing else.\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_request}\n",
    "    ]\n",
    "\n",
    "    # 4. Ask the model what tool to call\n",
    "    response = llm.chat.completions.create(model=\"gpt-4\", messages=messages) # Updated API call\n",
    "    assistant_message = response.choices[0].message.content.strip()\n",
    "\n",
    "    # 5. Parse the model’s JSON response\n",
    "    call = json.loads(assistant_message)\n",
    "    tool_name = call[\"tool\"]\n",
    "    params = call.get(\"params\", {})\n",
    "\n",
    "    # 6. Invoke the MCP server\n",
    "    try:\n",
    "        result = mcp.invoke(tool_name, params)\n",
    "        print(f\"Result from '{tool_name}':\\n{result}\")\n",
    "    except MCPError as e:\n",
    "        print(f\"MCP Error ({e.code}): {e.message}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
